{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 21:47:36,504 loading paper_source_trace_train_ans.json ...\n",
      "2024-06-12 21:47:36,534 paper_source_trace_train_ans.json loaded\n",
      "2024-06-12 21:47:36,535 loading paper_source_trace_valid_wo_ans.json ...\n",
      "2024-06-12 21:47:36,543 paper_source_trace_valid_wo_ans.json loaded\n",
      "2024-06-12 21:47:36,544 loading paper_source_trace_test_wo_ans.json ...\n",
      "2024-06-12 21:47:36,553 paper_source_trace_test_wo_ans.json loaded\n"
     ]
    }
   ],
   "source": [
    "## 尝试做特征\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict as dd\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, average_precision_score\n",
    "import logging\n",
    "\n",
    "import utils\n",
    "import settings\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "data_dir = settings.DATA_TRACE_DIR\n",
    "\n",
    "papers_train = utils.load_json('', \"paper_source_trace_train_ans.json\")\n",
    "papers_valid = utils.load_json('', \"paper_source_trace_valid_wo_ans.json\")\n",
    "papers_test = utils.load_json('',  \"paper_source_trace_test_wo_ans.json\")\n",
    "\n",
    "\n",
    "files = []\n",
    "data_dir = './'\n",
    "in_dir = join(data_dir, 'paper-xml')\n",
    "for f in os.listdir(in_dir):\n",
    "    if f.endswith('.xml'):\n",
    "        files.append(f)\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import collections\n",
    "import json\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z]+', ' ', text).lower().strip()\n",
    "\n",
    "import re\n",
    "def get_pattern(input_string):\n",
    "    pattern = r'\\n\\n(.*?)\\n\\n'\n",
    "\n",
    "# 执行正则表达式搜索\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    # 检查是否有匹配，如果有，则输出匹配到的内容\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "## test\n",
    "id_train = [ x['_id'] for x in papers_train]\n",
    "id_valid = [ x['_id'] for x in papers_valid]\n",
    "id_test = [ x['_id'] for x in papers_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file, in_dir):\n",
    "    '''\n",
    "    读取XML格式论文文件\n",
    "    '''\n",
    "    file_path = join(in_dir, file)\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "    xml = f.read()\n",
    "    bs = BeautifulSoup(xml, \"xml\")    \n",
    "    return xml, bs\n",
    "\n",
    "def get_ref_list(bs):\n",
    "    '''\n",
    "    获取输入文件中所有引用对应的标题\n",
    "    输入: bs格式的论文XML文件\n",
    "    输出: dict格式的论文引用标题\n",
    "    '''\n",
    "    this_ref_list = {}\n",
    "    references = bs.find_all(\"biblStruct\")\n",
    "    for ref in references:\n",
    "        key = ref.get('xml:id')\n",
    "        try:\n",
    "            title = ref.find('title', level=\"a\").get_text()\n",
    "        except:\n",
    "            try:\n",
    "                title = ref.find('title', level=\"m\").get_text()\n",
    "            except:\n",
    "                title = ref.getText()\n",
    "                title = get_pattern(title)\n",
    "        this_ref_list[key] = clean_text(title)\n",
    "    return this_ref_list\n",
    "\n",
    "\n",
    "def get_body_ref_count(body):\n",
    "    '''\n",
    "    获取论文引用数目\n",
    "    输入: bs格式的论文XML文件\n",
    "    输出: dict格式的论文引用数目\n",
    "    '''\n",
    "    #找到正文\n",
    "    references = body.find_all('ref', type='bibr')\n",
    "    reference_counter = collections.Counter()\n",
    "    for reference in references:\n",
    "        if reference.has_attr('target'):\n",
    "            reference_counter[reference['target'].strip(\"#\")] += 1\n",
    "    return reference_counter\n",
    "\n",
    "\n",
    "def get_bs_title(bs):\n",
    "    '''\n",
    "    获取标题\n",
    "    '''\n",
    "    ##--------------------- pid_to_title / title_to_pid --------------------------\n",
    "    title = clean_text(bs.find(lambda tag: tag.name == \"title\" and tag.get('type') == 'main').text)\n",
    "    return title\n",
    "\n",
    "\n",
    "    ##--------------------- authors_info_dict --------------------------\n",
    "def get_author_info(bs):\n",
    "    authors_info = []\n",
    "    authors = bs.find_all('author')\n",
    "\n",
    "    # Loop through all authors and extract name and affiliation\n",
    "    for author in authors:\n",
    "        # Extracting the author's name (forename and surname)\n",
    "        if author.affiliation:\n",
    "            try:\n",
    "                forename = author.forename.get_text(strip=True)\n",
    "                surname = author.surname.get_text(strip=True)\n",
    "                try:\n",
    "                    country = author.find('country').get_text(strip=True)\n",
    "                except:\n",
    "                    country = \"\"\n",
    "                org_names = author.find_all('orgName', attrs={\"type\": \"institution\"})\n",
    "                authors_info.append({\n",
    "                    \"forename\": forename,\n",
    "                    \"surname\": surname,\n",
    "                    \"country\": country,\n",
    "                    \"org_names\": [org_name.get_text(strip=True) for org_name in org_names]\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return authors_info\n",
    "\n",
    "def find_bib_context(xml, bs, dist=100):\n",
    "    bib_to_context = dd(list)\n",
    "    bibr_strs_to_bid_id = {}\n",
    "    for item in bs.find_all(type='bibr'):\n",
    "        if \"target\" not in item.attrs:\n",
    "            continue\n",
    "        bib_id = item.attrs[\"target\"][1:]\n",
    "        item_str = \"<ref type=\\\"bibr\\\" target=\\\"{}\\\">{}</ref>\".format(item.attrs[\"target\"], item.get_text())\n",
    "        bibr_strs_to_bid_id[item_str] = bib_id\n",
    "\n",
    "    for item_str in bibr_strs_to_bid_id:\n",
    "        bib_id = bibr_strs_to_bid_id[item_str]\n",
    "        cur_bib_context_pos_start = [ii for ii in range(len(xml)) if xml.startswith(item_str, ii)]\n",
    "        for pos in cur_bib_context_pos_start:\n",
    "            bib_to_context[bib_id].append(xml[pos - dist: pos + dist].replace(\"\\n\", \" \").replace(\"\\r\", \" \").strip())\n",
    "    return bib_to_context\n",
    "\n",
    "def  get_bib_context(bs, xml):\n",
    "    return find_bib_context(xml, bs)\n",
    "\n",
    "def find_section_number(header):\n",
    "    if not header:\n",
    "        return None\n",
    "    \n",
    "    section_number = header.get('n')\n",
    "    \n",
    "    if section_number:\n",
    "        return section_number\n",
    "\n",
    "    \n",
    "    text = header.text\n",
    "    \n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    if 'I.' in text or 'introduction' in text.lower():\n",
    "        return '1.'\n",
    "    if 'II.' in text or 'related' in text.lower():\n",
    "        return '2.'\n",
    "    if 'III.' in text or 'method' in text.lower():\n",
    "        return '3.'\n",
    "    if 'IV.' in text:\n",
    "        return '4.'\n",
    "    if 'V.' in text:\n",
    "        return '5.'\n",
    "    if 'VI.' in text:\n",
    "        return '6.'\n",
    "    if 'VII.' in text:\n",
    "        return '7.'\n",
    "    if 'VIII.' in text:\n",
    "        return '8.'\n",
    "    if 'IX.' in text:\n",
    "        return '9.'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_section_bib_number(bs):\n",
    "    sections = bs.find_all(\"div\")\n",
    "    reference_counter_1 = collections.Counter()\n",
    "    reference_counter_2 = collections.Counter()\n",
    "    reference_counter_3 = collections.Counter()\n",
    "    reference_counter_4 = collections.Counter()\n",
    "    reference_counter_5 = collections.Counter()\n",
    "    reference_counter_6 = collections.Counter()\n",
    "\n",
    "    now_section_index = 0\n",
    "\n",
    "    for section in sections:\n",
    "        if not section.find('head'):\n",
    "            continue\n",
    "        \n",
    "        header = section.find(\"head\")\n",
    "        #section_number = header.get('n')\n",
    "        section_number = find_section_number(header)\n",
    "\n",
    "        #if not section_number:\n",
    "        #    continue\n",
    "\n",
    "        if section_number:\n",
    "\n",
    "            section_index = int(section_number.split('.')[0])\n",
    "            section_title = header.text.strip()\n",
    "            now_section_index = section_index\n",
    "\n",
    "        references = section.find_all('ref', type='bibr')\n",
    "        for reference in references:\n",
    "            if reference.has_attr('target'):\n",
    "                if now_section_index == 1:\n",
    "                    reference_counter_1[reference['target'].strip(\"#\")] += 1\n",
    "                elif now_section_index == 2:\n",
    "                    reference_counter_2[reference['target'].strip(\"#\")] += 1\n",
    "                elif now_section_index == 3:\n",
    "                    reference_counter_3[reference['target'].strip(\"#\")] += 1\n",
    "                elif now_section_index == 4:\n",
    "                    reference_counter_4[reference['target'].strip(\"#\")] += 1\n",
    "                elif now_section_index == 5:\n",
    "                    reference_counter_5[reference['target'].strip(\"#\")] += 1\n",
    "                elif now_section_index == 6:\n",
    "                    reference_counter_6[reference['target'].strip(\"#\")] += 1\n",
    "        \n",
    "        return reference_counter_1, reference_counter_2, reference_counter_3, reference_counter_4, reference_counter_5, reference_counter_6\n",
    "    \n",
    "\n",
    "## 解析原文的feat\n",
    "\n",
    "Chinese_surname_list = ['li', 'wang', 'zhang', 'liu', 'chen', 'yang', 'huang', 'zhao', 'wu', 'zhou', 'xiong', 'xiu', 'sun', 'ma', 'zhu', 'hu', 'guo', 'he', 'gao', 'lin', 'luo', 'zheng', 'qian', 'zhen', 'tong', 'zeng', 'zen', 'zhuang',\n",
    "                        'liang', 'xie', 'song', 'tang', 'dong', 'yuan', 'cai', 'feng', 'xiao', 'jiang', 'shi', 'hang', 'ang', 'ong', 'ie', \n",
    "                        'xu', 'sun', 'ma', 'zhu', 'hu', 'guo', 'he', 'gao', 'lin', 'luo', 'zheng', 'qian', 'zhen', 'tong', 'zeng', 'zen', 'zhuang',\n",
    "                        'liang', 'xie', 'song', 'tang', 'dong', 'yuan', 'cai', 'feng', 'xiao', 'jiang', 'shi', 'hang', 'ang', 'ong', 'ie', 'chua',\n",
    "                        'tian', 'jia', 'pan', 'du', 'dai', 'wei', 'yu', 'bai', 'han', 'gu', 'yao', 'kuang', 'shuang','qi','mei']\n",
    "\n",
    "def get_num_author_source(paper):\n",
    "    surname_list = [x['name'] for x in paper['authors']]\n",
    "    num_author = len(surname_list)\n",
    "    return num_author\n",
    "\n",
    "def get_num_chinese_author_source(paper):\n",
    "    surname_list = [x['name'] for x in paper['authors']]\n",
    "    surname_list = [x.split(' ')[-1] for x in surname_list]\n",
    "    chinese_author_list = [x for x in surname_list if x.lower() in Chinese_surname_list]\n",
    "    return len(chinese_author_list)\n",
    "\n",
    "\n",
    "## 引用的信息\n",
    "\n",
    "def get_reference_info(bs):\n",
    "    this_paper_list = {}\n",
    "    references = bs.find_all(\"biblStruct\") \n",
    "    for ref in references:\n",
    "        key = ref.get('xml:id')\n",
    "        this_ref_list = {}\n",
    "        surname_list = [surname.get_text() for surname in ref.find_all(\"surname\")]\n",
    "        this_ref_list['num_author'] = len(surname_list)\n",
    "        this_ref_list['num_chinese_author'] = len([x for x in surname_list if x.lower() in Chinese_surname_list])\n",
    "        try:\n",
    "            journal = ref.find(\"title\", {\"level\": \"m\"}) or ref.find(\"title\", {\"level\": \"j\"})\n",
    "            journal = journal.get_text()\n",
    "        except:\n",
    "            journal = \"\"\n",
    "        this_ref_list['journal'] = journal\n",
    "        this_paper_list[key] = this_ref_list\n",
    "    return this_paper_list\n",
    "\n",
    "    \n",
    "def extract_text(bs):\n",
    "    sections = bs.find_all('div', limit=10) \n",
    "    total_text = []\n",
    "    for i, section in enumerate(sections):\n",
    "        # 处理引用标记\n",
    "        for ref in section.find_all('ref', type='bibr'):\n",
    "            # 获取编号，假设target属性类似于\"#b20\"\n",
    "            try:\n",
    "                ref_num = re.search(r'#b(\\d+)', ref.get('target'))\n",
    "                if ref_num:\n",
    "                    # 将 ref 替换为如 [b20]\n",
    "                    ref.replace_with('[b{}]'.format(ref_num.group(1)))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # 从div标签中提取文本\n",
    "        text = section.get_text(separator=' ', strip=True)\n",
    "        total_text.append(text)\n",
    "    return total_text\n",
    "\n",
    "\n",
    "### 首先洗一遍数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "from typing import List, Union\n",
    "\n",
    "class PaperParser:\n",
    "    def __init__(self, bs, xml):\n",
    "        self.paper_id = None\n",
    "        self.title = None \n",
    "        self.body = None\n",
    "        self.bs = bs\n",
    "        self.xml = xml\n",
    "        self.ref_info = {}\n",
    "        self.preprocess()\n",
    "        self.extract_ref_author_info()\n",
    "        self.check_reference()\n",
    "\n",
    "    def check_reference(self):\n",
    "        unnumbered_references_texts = []\n",
    "        numbered_references_texts = []\n",
    "        for ref in self.references:\n",
    "            if not ref.has_attr('target'):\n",
    "                unnumbered_references_texts.append(ref.get_text())\n",
    "            else:\n",
    "                numbered_references_texts.append(ref.get_text())\n",
    "        \n",
    "        self.unnumbered_references_texts = unnumbered_references_texts\n",
    "        self.numbered_references_texts = numbered_references_texts\n",
    "        self.n_ref_valid = len(self.numbered_references_texts)\n",
    "        self.n_ref_invalid = len(self.unnumbered_references_texts)\n",
    "\n",
    "\n",
    "    def extract_references_from_text_digit(self, text) -> Union[List[int], None]:\n",
    "        # 定义正则表达式，用于匹配引用格式\n",
    "        pattern = re.compile(r'\\[\\s*(\\d+(?:\\s*;\\s*\\d+)*)\\s*\\]')\n",
    "        \n",
    "        # 在文本中搜索匹配的模式\n",
    "        matches = pattern.findall(text)\n",
    "        \n",
    "        # 用于存储解析后的引用序号\n",
    "        references = []\n",
    "        \n",
    "        # 如果找到匹配模式，解析引用序号\n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                # 分割每个匹配到的文本，并转换成整数序号\n",
    "                refs = match.split(';')\n",
    "                for ref in refs:\n",
    "                    references.append(int(ref.strip()))  # 移除可能的空格，并将文本转换成整数\n",
    "            return 'b' + str(references[0] - 1)\n",
    "        else:\n",
    "            return None  # 如果没有找到匹配，则返回None\n",
    "\n",
    "    def extract_ref_author_info(self):\n",
    "        '''\n",
    "        获取作者信息, key为b_key\n",
    "        '''\n",
    "\n",
    "        def extract_year(ref):\n",
    "            return ref.find('date', {'type': 'published'}).get('when')\n",
    "        \n",
    "        def extract_year_v2(ref):\n",
    "            # 使用BeautifulSoup解析XML数据\n",
    "            \n",
    "            # 寻找所有的<biblScope>标签\n",
    "            bibl_scope_tags = ref.find_all('biblScope')\n",
    "            \n",
    "            # 遍历找到的标签，寻找可能包含年份信息的标签\n",
    "            for tag in bibl_scope_tags:\n",
    "                if tag.get('unit') == 'page':\n",
    "                    # 尝试将内容转换为整数，以验证其是否可能是年份\n",
    "                    try:\n",
    "                        year = int(tag.text)\n",
    "                        # 根据需要可以添加更多的验证步骤，例如检查年份范围等\n",
    "                        # 如果内容成功转换为整数，并且看起来像合理的年份，返回它\n",
    "                        if 1900 <= year <= 2100:\n",
    "                            return tag.text\n",
    "                    except ValueError:\n",
    "                        # 如果内容不能转换为整数，继续遍历\n",
    "                        continue\n",
    "            \n",
    "            return None\n",
    "\n",
    "\n",
    "        def extract_year_from_title(ref):\n",
    "            # 使用BeautifulSoup解析XML数据\n",
    "            \n",
    "            # 寻找<title>标签\n",
    "            title_tag = ref.find('title')\n",
    "            \n",
    "            if title_tag:\n",
    "                # 使用正则表达式从标题文本中提取年份\n",
    "                match = re.search(r'\\b(\\d{4})\\b', title_tag.text)\n",
    "                if match:\n",
    "                    return match.group(1)\n",
    "            \n",
    "            return None\n",
    "        \n",
    "        for ref in self.references_bib:\n",
    "            #title_tag = ref.find('title')\n",
    "            suffix = None\n",
    "            key = ref.get('xml:id')\n",
    "            try:\n",
    "                first_author = [surname.get_text() for surname in ref.find_all(\"surname\")][0]\n",
    "            except:\n",
    "                first_author = None\n",
    "            try:\n",
    "                ref_years = extract_year(ref)\n",
    "            except:\n",
    "                try:\n",
    "                    ref_years = extract_year_v2(ref)\n",
    "                except:\n",
    "                    try:\n",
    "                        ref_years = extract_year_from_title(ref)\n",
    "                    except:\n",
    "                        ref_years = None\n",
    "\n",
    "            if ref_years:\n",
    "                if '-' in ref_years:\n",
    "                    ref_years = ref_years[:4]\n",
    "        \n",
    "\n",
    "            self.ref_info[key] = {'first_author': first_author, 'ref_years': ref_years}\n",
    "\n",
    "\n",
    "    def infer_ref_number_from_text(self, text):\n",
    "        '''返回如b1...'''\n",
    "        ## 第一种情况, ... et al.的形式\n",
    "        ## 从解析的ref_info去匹配\n",
    "        # 用于匹配年份且不以字母结尾的正则表达式\n",
    "        #print('start')\n",
    "        regex_no_letter = re.compile(r'\\d{4}(?!\\w)')\n",
    "\n",
    "        # 用于匹配年份以字母结尾的正则表达式\n",
    "        regex_with_letter = re.compile(r'\\d{4}\\w')\n",
    "\n",
    "        good_match = []\n",
    "\n",
    "        #先匹配作者名字\n",
    "        author_name_match = []\n",
    "        for key, value in self.ref_info.items():\n",
    "            if key is None:\n",
    "                continue\n",
    "            first_author, ref_years = value['first_author'], value['ref_years']\n",
    "            #print(f'first_author is {first_author}, ref_years is {ref_years}')\n",
    "            if first_author is not None and text is not None:\n",
    "                if first_author.lower() in text.lower():\n",
    "                    author_name_match.append(key)\n",
    "\n",
    "        #print(f'author_name_match is {author_name_match}')\n",
    "        \n",
    "        if len(author_name_match) == 1:\n",
    "                return author_name_match[0]\n",
    "        \n",
    "        ## 否则，需要按年份来匹配\n",
    "        for key, value in self.ref_info.items():\n",
    "            if key is None:\n",
    "                continue\n",
    "            first_author, ref_years = value['first_author'], value['ref_years']\n",
    "            #print(f'first_author is {first_author}, ref_years is {ref_years}, text is {text}')\n",
    "            if first_author is not None and text is not None and ref_years is not None:\n",
    "                if first_author.lower() in text.lower() and ref_years in text:\n",
    "                    good_match.append((key, value))\n",
    "\n",
    "        #print(f'good_match is {good_match}')\n",
    "        \n",
    "        if len(good_match) == 1:\n",
    "            return key\n",
    "        \n",
    "        elif len(good_match) > 1:\n",
    "            # 多个匹配\n",
    "            ## 检查以abc结尾\n",
    "            if regex_with_letter.search(text):\n",
    "                ## 找到最后的那个字母\n",
    "                last_letter = regex_with_letter.search(text).group()[-1]\n",
    "                if last_letter == 'a':\n",
    "                    return good_match[0][0]\n",
    "                elif last_letter == 'b':\n",
    "                    return good_match[1][0]\n",
    "                elif last_letter == 'c' and len(good_match) > 2:\n",
    "                    return good_match[2][0]\n",
    "                elif last_letter == 'd' and len(good_match) > 3:\n",
    "                    return good_match[3][0]\n",
    "                else:\n",
    "                    return good_match[0][0]\n",
    "\n",
    "\n",
    "        elif len(good_match) == 0:\n",
    "            ## 猜测是数字的形式\n",
    "            if self.extract_references_from_text_digit(text):\n",
    "                return self.extract_references_from_text_digit(text)\n",
    "        \n",
    "        if len(author_name_match) > 0:\n",
    "            return author_name_match[0]\n",
    "                    \n",
    "        return None\n",
    "            \n",
    "    def replace_refs_with_inferred_numbers(self, body):\n",
    "\n",
    "        self.body_raw = body\n",
    "\n",
    "        # 找到所有的引用标签\n",
    "        refs = body.find_all('ref', type=\"bibr\")\n",
    "        \n",
    "        for ref in refs:\n",
    "            if not ref.has_attr('target'):  # 如果没有 target 属性，则尝试推断引用编号\n",
    "                #print(f'ref.text is {ref.text}')\n",
    "                inferred_ref_number = self.infer_ref_number_from_text(ref.text)\n",
    "                #print(inferred_ref_number)\n",
    "                if inferred_ref_number is not None:\n",
    "                    ref['target'] = '#' + inferred_ref_number  # 添加推断出的编号\n",
    "                    ref.string = \"{} ({})\".format(ref.text, inferred_ref_number)\n",
    "        \n",
    "        # 返回处理后的XML数据\n",
    "        self.body_processed = body\n",
    "        \n",
    "        \n",
    "\n",
    "    def preprocess(self):\n",
    "        '''\n",
    "        初步的解析\n",
    "        '''\n",
    "        self.body = self.bs.find('body')\n",
    "        self.references = self.body.find_all('ref', type='bibr')\n",
    "        self.references_bib = self.bs.find_all(\"biblStruct\")\n",
    "\n",
    "        ### Check 引用\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'The paper with id {self.paper_id}, title {self.title}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7541 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7541/7541 [01:04<00:00, 117.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# 结果的记录\n",
    "submission_ref_list = {}\n",
    "submission_ref_year_list = {}\n",
    "body_ref_count = {}\n",
    "pid_to_title = {}\n",
    "title_to_pid = {}\n",
    "authors_info_dict = {}\n",
    "bib_to_contexts_dict = {}\n",
    "total_author_data_sup = {}\n",
    "\n",
    "body_ref_count_1 = {}\n",
    "body_ref_count_2 = {}\n",
    "body_ref_count_3 = {}\n",
    "body_ref_count_4 = {}\n",
    "body_ref_count_5 = {}\n",
    "body_ref_count_6 = {}\n",
    "\n",
    "other_featuers = {}\n",
    "\n",
    "total_id = id_train + id_valid + id_test\n",
    "\n",
    "papers_list = {}\n",
    "\n",
    "for file in tqdm(files):\n",
    "\n",
    "    # 读文件\n",
    "    paper_key = file.split('.')[0]\n",
    "\n",
    "    # 无关数据不处理\n",
    "    if paper_key not in total_id:\n",
    "        continue\n",
    "\n",
    "    xml, bs = read_file(file, in_dir)\n",
    "    paper = PaperParser(bs = bs, xml = xml)\n",
    "    body = bs.find('body')\n",
    "    paper.replace_refs_with_inferred_numbers(body)\n",
    "    papers_list[paper_key] = paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7541/7541 [11:30<00:00, 10.92it/s]  \n"
     ]
    }
   ],
   "source": [
    "iii = 0\n",
    "for file in tqdm(files):\n",
    "\n",
    "    # 读文件\n",
    "    paper_key = file.split('.')[0]\n",
    "\n",
    "    # 无关数据不处理\n",
    "    if paper_key not in total_id:\n",
    "        continue\n",
    "\n",
    "    iii = iii + 1\n",
    "    xml, bs = read_file(file, in_dir)\n",
    "\n",
    "    # 获取处理过的paper\n",
    "    paper = papers_list[paper_key]\n",
    "\n",
    "    body = paper.body_processed\n",
    "\n",
    "    this_ref_list = get_ref_list(bs)\n",
    "\n",
    "    ## 获取论文引用标题\n",
    "    submission_ref_list[paper_key] = this_ref_list\n",
    "\n",
    "    ## 获取论文引用数目 \n",
    "    body_ref_count[paper_key] = get_body_ref_count(body)\n",
    "\n",
    "    title = get_bs_title(bs)\n",
    "\n",
    "    pid_to_title[paper_key] = title\n",
    "    title_to_pid[title] = paper_key\n",
    "\n",
    "    ## 获取作者信息\n",
    "    authors_info = get_author_info(bs)\n",
    "    authors_info_dict[paper_key] = authors_info\n",
    "\n",
    "    # 获取引用上下文信息\n",
    "    bib_to_contexts_dict[paper_key] = get_bib_context(bs, xml)\n",
    "\n",
    "    ## 获取段落引用信息\n",
    "    reference_counter_1, reference_counter_2, reference_counter_3, reference_counter_4, reference_counter_5, reference_counter_6 = get_section_bib_number(bs)\n",
    "    body_ref_count_1[paper_key] = reference_counter_1\n",
    "    body_ref_count_2[paper_key] = reference_counter_2\n",
    "    body_ref_count_3[paper_key] = reference_counter_3\n",
    "    body_ref_count_4[paper_key] = reference_counter_4\n",
    "    body_ref_count_5[paper_key] = reference_counter_5\n",
    "    body_ref_count_6[paper_key] = reference_counter_6\n",
    "\n",
    "    total_author_data_sup[paper_key] = get_reference_info(bs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存文件\n",
    "processed_data = (submission_ref_list, \n",
    "                  body_ref_count, \n",
    "                  pid_to_title, \n",
    "                  title_to_pid, \n",
    "                  authors_info_dict, \n",
    "                  body_ref_count_1,\n",
    "                  body_ref_count_2,\n",
    "                  body_ref_count_3,\n",
    "                  body_ref_count_4,\n",
    "                  body_ref_count_5,\n",
    "                  body_ref_count_6, total_author_data_sup, bib_to_contexts_dict)\n",
    "\n",
    "## saved processed_data\n",
    "import pickle\n",
    "processed_data_name = 'processed_data_0601.pickle'\n",
    "with open(processed_data_name, 'wb') as f:\n",
    "    pickle.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:00<00:00, 1468.20it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 1355.73it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 1435.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n",
      "394\n",
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### 做GPT prompt\n",
    "#### 第一类prompt: 直接给Inspiration基于结果的打分\n",
    "## prompt \n",
    "def get_prompt_gpt_short_3(text):\n",
    "    return f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text. \n",
    "                **** I will now give you a text of academic papers, to find the most pertinent source papers:\n",
    "                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\n",
    "                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper's core contributions.\n",
    "                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\n",
    "                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\n",
    "                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper's topic.\n",
    "                Verify that the source papers are directly relevant to the paper's novel contributions very directly.\n",
    "                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as 'Inspired by [reference]', and make these references a priority in the list\n",
    "                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \n",
    "                **** Normally you should return less than 8 source papers. ****\n",
    "                **** Please re-evaluate your result by the following metric: \t\tIs the main idea of paper p inspired by the reference？\n",
    "* \t\tIs the core method of paper p derived from the reference？\n",
    "* \t\tIs the reference essential for paper p? Without the work of this reference, paper p cannot be completed. \n",
    "Then, you should return your result in the json format, with the key is “reference number” and the value is “confidence score” between 0 and 1.\n",
    "                **** The text of the paper is:{text}'''\n",
    "\n",
    "## prompt \n",
    "def get_prompt_gpt_short_3(text):\n",
    "    return f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text. \n",
    "                **** I will now give you a text of academic papers, to find the most pertinent source papers:\n",
    "                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\n",
    "                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper's core contributions.\n",
    "                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\n",
    "                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\n",
    "                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper's topic.\n",
    "                Verify that the source papers are directly relevant to the paper's novel contributions very directly.\n",
    "                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as 'Inspired by [reference]', and make these references a priority in the list\n",
    "                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \n",
    "                **** Normally you should return less than 8 source papers. ****\n",
    "                **** Please re-evaluate your result by the following metric: \t\tIs the main idea of paper p inspired by the reference？\n",
    "* \t\tIs the core method of paper p derived from the reference？\n",
    "* \t\tIs the reference essential for paper p? Without the work of this reference, paper p cannot be completed. \n",
    "Then, you should return your result in the json format, with the key is “reference number” and the value is “confidence score” between 0 and 1.\n",
    "                **** The text of the paper is:{text}'''\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_train = {}\n",
    "for paper_key in tqdm(id_train):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_short_3(text)\n",
    "    total_prompt_train[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_train.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_train, f)\n",
    "\n",
    "\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_valid = {}\n",
    "for paper_key in tqdm(id_valid):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_short_3(text)\n",
    "    total_prompt_valid[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_valid.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_valid, f)\n",
    "\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_test = {}\n",
    "for paper_key in tqdm(id_test):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_short_3(text)\n",
    "    total_prompt_test[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_test.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_test, f)\n",
    "\n",
    "print(len(total_prompt_train))\n",
    "print(len(total_prompt_valid))\n",
    "print(len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:00<00:00, 3570.39it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 3361.60it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 3457.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n",
      "394\n",
      "394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### 做GPT prompt\n",
    "#### 第二类prompt: 给出Inspiration基于结果的分级\n",
    "## prompt \n",
    "def get_prompt_gpt_json(text):\n",
    "    return f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text.\n",
    "                **** I will now give you a text of academic papers, to find the most pertinent source papers:\n",
    "                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\n",
    "                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper's core contributions.\n",
    "                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\n",
    "                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\n",
    "                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper's topic.\n",
    "                Verify that the source papers are directly relevant to the paper's novel contributions very directly.\n",
    "                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as 'Inspired by [reference]', and make these references a priority in the list\n",
    "                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \n",
    "                **** Normally you should return less than 8 source papers. ****\n",
    "                **** please give your answer in four parts: 0. **Summary of the challenges and inspirations of the paper**; 1. **Direct Inspiration/Motivation**; 2.** Indirect Inspiration/Motivation**; 3.**Other important ispiration/motivation**, and You MUST return the reference number in the answer.\n",
    "                **** please give your answer in four parts in the json format with keys ['Summary','Direct Inspiration','Indirect Inspiration','Other Inspiration'], and return the reference number in the format of b1, b2... \n",
    "                **** The text of the paper is:{text}'''\n",
    "\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_train = {}\n",
    "for paper_key in tqdm(id_train):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_json(text)\n",
    "    total_prompt_train[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_train.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_train, f)\n",
    "\n",
    "\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_valid = {}\n",
    "for paper_key in tqdm(id_valid):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_json(text)\n",
    "    total_prompt_valid[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_valid.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_valid, f)\n",
    "\n",
    "\n",
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_test = {}\n",
    "for paper_key in tqdm(id_test):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_json(text)\n",
    "    total_prompt_test[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_test.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_test, f)\n",
    "\n",
    "print(len(total_prompt_train))\n",
    "print(len(total_prompt_valid))\n",
    "print(len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text.\\n                **** I will now give you a text of academic papers, to find the most pertinent source papers:\\n                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\\n                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper\\'s core contributions.\\n                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\\n                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\\n                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper\\'s topic.\\n                Verify that the source papers are directly relevant to the paper\\'s novel contributions very directly.\\n                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as \\'Inspired by [reference]\\', and make these references a priority in the list\\n                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \\n                **** Normally you should return less than 8 source papers. ****\\n                **** please give your answer in four parts: 0. **Summary of the challenges and inspirations of the paper**; 1. **Direct Inspiration/Motivation**; 2.** Indirect Inspiration/Motivation**; 3.**Other important ispiration/motivation**, and You MUST return the reference number in the answer.\\n                **** please give your answer in four parts in the json format with keys [\\'Summary\\',\\'Direct Inspiration\\',\\'Indirect Inspiration\\',\\'Other Inspiration\\'], and return the reference number in the format of b1, b2... \\n                **** The text of the paper is:Introduction Short text matching is an essential task that has been applied in question answering [b0] , paraphrase identification [b13] and information retrieval [b7] . In recent years, deep neural networks achieve surprising performance in this field. We can roughly classify deep text matching models into two types: 1) representation-based text matching [b7] [b12] and 2) interaction-based text matching [b17] [b18] [b6] . The interactive-based framework is usually performs better than the representation-based framework. Though interactive-based framework achieved very promising results, their performance still suffers from the lack of enough contextual information since words or expressions in a short text usually have ambiguous meanings. Especially in Chinese scenarios, both characterlevel and word-level tokenization introduce serious  semantic information errors or missing. Recent studies show that encoding multi-granularity information [b8] [b3] and word sense information [b10] into sentences can mitigate this problem. They further improve the performance, while this word-level information reinforces is still helpless in many cases that need relevant sentence-level contextual information supplement. As seen in Figure 1 , sentences 1 and 2 refer to the same question but the word-level semantic information is not enough to connect them. Therefore, we take the original sentences as queries to search related contexts by search engines. The retrieved contexts usually contain enough contextual information to relate the two original short texts. In this case, both short texts refer to \"interest of bank loan\", where the matching model could easily classify them to be matched. From this insight, we propose a context-aware BERT matching model (CBM) for short text matching, which enrich the semantic representation of a short text by external semantic-related sentences, arXiv:2203.01849v1 [cs.CL] 3 Mar 2022 instead of word-levle knowledge. As seen in Figure 1 , both sentences have multiple related contextual sentences 1 . CBM selects the needed contexts and updates the short text representation according to the context-enhanced attention mechanism. Our experiments on two Chinese datasets and one English dataset show that our model achieves new state-of-the-art performance. Our contributions are three folds: ? We are the first to propose a framework that enhances short text representation by external sentence-level knowledge. ? We crawled a huge amount of contextual sentences for the three commonly used benchmark datasets, which benefits future research. ? We design a simple but efficient model to utilize the sentences for short text representation reinforcement. Experiments show that our model achieves new SoTA performance..Framework Given two sentences, S a = {s 1 a , s 2 a , ..., s i a , ..., s n a } and S b = {s 1 b , s 2 b , ..., s j b , ..., s m b }, we aim to decide whether two sentences have the same semantic meaning. s i a and s j b denotes the i-th and j-th token in sentence a and b, respectively. Different from existing methods, we not only use the sentences in datasets, but also utilize the external sentences crawled from search engines to enhance the context. Each sentence S i has a set of contexts: C i = {c 1 i , c 2 i , ..., c j i , ..., c n i } , where c j i represents the j-th context for sentence S i . Our framework has three modules: 1) Contexts Crawler, 2) Context Selector, and 3) Contextenhanced Text Matcher..Context Crawler For each sentence S i , we obtain the set of contexts C i corresponding to S i by crawling the search engine results. The retrieved contexts C i are noisy and dirty, so we first remove the noise by preprocessing and perform a regular cleaning. Also, all contents related to personal information is removed. Finally, we will have a clean context set C i for each sentence S i ..Context Selector First, we use BERT baseline model to perform semantic similarity task for each pair of sentence and 1 We denote a contextual sentence as a context for short. context, S a with c j b or S b with c j a . Aftrer that, each pair of a sentence and a context has a similarity score of d j i , higher means higher semantic similarity, lower means lower semantic similarity. For instance, d j a is the similarity score for the pair of S a and c j b . For all positive samples (S a and S b are semantically matched), we use the hyperparameter d a to classify the context and sentence pairs into similar or dissimilar. All d j i > d a is similar and others are dissimilar. Otherwise, for all negative samples (S j a and S j b are not semantically matched), we use the hyperparameter d b to classify the context and sentence pairs into similar and dissimilar, with all d j i > d b being similar and the rest being dissimilar. For all positive samples, S + a and S + b , we want the context of S + a to have similar semantic information as S + b . Also, we want the context of S + b to have similar semantic information as S + a . On the contrary, for all negative samples, S - a and S - b , we expect the contexts of S - a to be semantically dissimilar to S - b . It is also expected that the contexts of S - b are not semantically similar to S - a . However, we do not have ground truth labels for test set to make the context selection by labels. Therefore, we construct a context selector to determine whether we want to use the context based on the semantic information of the two sentences and the context. When we construct contexts for the above positive and negative samples, using similar semantic contexts for positive samples and dissimilar semantic contexts for negative samples. We first put this data as pseudo labels into a BERT classifier for training. The inputs are S a , S b , c j i , where i ? [a, b], and the model output will be [0, 1], indicating whether this context will be used or not. Finally, the context selector integrates all relevant contexts into one context set, ?..Context-enhanced Text Matcher.Matching Classifier Our model predict predict the text similarity of two context-enhanced text representations. h f inal = [h a ; h b ; |h a -h b |] (1) p i = F F N (h f inal ) (2) where FFN(?) is a feed forward network with two hidden layers and a output layer, a relu activation after each hidden layer. For each training sample {S a , S b , y}, we aim to minimize the BCE loss: L = - N i=1 (ylog(p i ) + (1 -y)log(1 -p)) (3) where y ? {0, 1} is the label of the i-th training sample and p ? {0, 1} is the prediction of our model taking the sentence pair as input..Result Selector Since not every pair of short texts need context enhancement, for those pairs have high confidence with BERT baseline, we will keep the results and logits. We set the output logits of BERT baseline and our model to be ?i and ?i , respectively. Then, the final result will be as follow: y i = ?i + ?i -1 (4) where y i ? {0, 1} is the final predicted label of i-th sample, and y i equal to 1 if y i is larger than or equal to 0.5. Otherwise, y i will be set to 0. 3 Experiments.Dataset We conduct our experiments on Bank Question (BQ) [b1] , large-scale Chinese question matching corpus (LCQMC) [b9] and the Quora Question Paraphrasing corpus (QQP) datasets for semantic textual similarity task. BQ is a large-scale domain-specific Chinese corpus for sentence semantic matching. It is collected from customer service logs by a Chinese bank. LCQMC is a large-scale chinese question matching corpus. It focuses on intent matching rather than paraphrase..Experiments ? BERT-Baseline: A chinese pretrained BERT, called Chinese-BERT-wwm, provided by [b5] . ? ERNIE 2.0: A continual pre-training framework named ERNIE 2.0 which incrementally builds pre-training tasks and then learn pretrained models on these constructed tasks via continual multi-task learning. [b15] ? LET-BERT [b10] : A Linguistic knowledge Enhanced graph Transformer (LET) to deal with word ambiguity using HowNet. ? ZEN 2.0 Base [b14] : An updated n-gram enhanced pre-trained encoder on Chinese and Arabic. ? GMN-BERT: A neural graph matching method (GMN) for Chinese short text matching. ? Glyce+BERT [b11] : Glyce provide glyph-vectors for logographic language representations. ? RoBERTa-wwm-ext-large: A chinese pretrained RoBERTa model which is also provided by [b5] . In Table 1 , both Bert Baseline and our model are the results of our tuning of the hyperparameters to the best. All other experimental results are using the best results on the corresponding paper. In comparison, our model results outperform all baselines on the BQ dataset and outperform the previous best model by nearly 2% in F1 values. On the LCQMC dataset, we also achieve the state of the art results..Details The BERT models used in our experiments are the  As seen in Table 2 , removing the context selector will hurt the performance significantly because the unfiltered contexts contain serious noise. If we randomly select k contexts, then the model could not take advantage of the context information since the contexts may be irrelevant. However, when we select K most relevant contexts, due to the properities of the search engine, contexts will be exactly the same or similar to short texts. Therefore, the contexts will turn out to be useless for the model. As a result, the ablation studies proves that the context selector module can effectively filter the noisy contexts and provide high-quality contexts for each short text. Our model shares the parameters in context encoder and short text encoder, then they could encode the contexts and short texts into the same semantic space. Finally, the ablation studies demostrate that sharing parameters boosts the performance and efficiency of the model.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_prompt_test['622183525aee126c0f23c7c2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 第三类Prompt: 只刷test\n",
    "def get_prompt_gpt_short_4(text):\n",
    "    return f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text. \n",
    "                **** I will now give you a text of academic papers, to find the most pertinent source papers:\n",
    "                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\n",
    "                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper's core contributions.\n",
    "                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\n",
    "                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\n",
    "                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper's topic.\n",
    "                Verify that the source papers are directly relevant to the paper's novel contributions very directly.\n",
    "                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as 'Inspired by [reference]', and make these references a priority in the list\n",
    "                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \n",
    "                **** Normally you should return less than 8 source papers. ****\n",
    "                **** You can also infer the answer by evaluating the titles of each paper. ****\n",
    "               **** You should re-evaluate your answer by: Emphasize Novel Contributions: Instead of broadly asking for \"challenges\", explicitly ask for the novel contributions of the paper. This helps focus the search for references that directly contribute to those specific aspects.\n",
    "Prioritize Methodological Similarity: Instruct the search to prioritize references that share strong methodological similarities with the paper being analyzed. For example, papers that also employ minimax optimization or focus on sample efficiency in data augmentation.\n",
    "Look for Comparative Phrases: Guide the search towards phrases that indicate comparisons with previous work, such as \"Unlike [reference], we...\", \"Improving upon [reference], our method...\", or \"Similar to [reference] in terms of [aspect], but...\".\n",
    "#**** Please think step by step. Then, you should return your result in the json format, with the key is “reference number” and the value is “confidence score” between 0 and 1.\n",
    "                **** The text of the paper is:{text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:00<00:00, 3139.50it/s]\n"
     ]
    }
   ],
   "source": [
    "### 刷prompt: get_prompt_gpt_short_3\n",
    "total_prompt_test = {}\n",
    "for paper_key in tqdm(id_test):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "    my_prompt = get_prompt_gpt_short_4(text)\n",
    "    total_prompt_test[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:00<00:00, 2594.60it/s]\n",
      "100%|██████████| 394/394 [00:00<00:00, 2777.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#### 第四类Prompt: 补充信息 test + train\n",
    "\n",
    "\n",
    "def get_prompt_gpt_short_5(text, author_note = None, refs_list = None):\n",
    "\n",
    "    part1 = f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text. \n",
    "                **** I will now give you a text of academic papers, to find the most pertinent source papers:\n",
    "                Firstly, Determine the primary challenges outlined in the paper, and understand the algorithm proposed by the author.\n",
    "                Then, look for key phrases such as \"inspired by\", \"motivated by\", \"inspired us\", \"motivated us\", \"take inspiration\", \"the pioneering/previous work\", \"following.. we adopt ... to solve the challenge/problem\", \"we use... based on to achieve...\" or other language that indicates a strong reliance on previous research for developing the paper's core contributions.\n",
    "                If key phrases exist, locate the key phrases in the text and find the sources papers which are indicated by these key phrases.\n",
    "                If key phrases do not exist or for other reasons, identify the novel methods and approaches the paper introduces to tackle these challenges and locate references that are directly linked to these main challenges and methods.\n",
    "                Verify that your answer do not include the ref papers appearing at the begining part of the text which describe the historical findings  like \"someone et al. proposed...\", normally they are not direct related to the paper's topic.\n",
    "                Verify that the source papers are directly relevant to the paper's novel contributions very directly.\n",
    "                Specifically highlight any references that are preceded by phrases indicating direct inspiration or motivation, such as 'Inspired by [reference]', and make these references a priority in the list\n",
    "                Please provide a concise list of source papers based on the aforementioned criteria, ideally limiting the selection to the most central references that heavily influenced the main contributions of the paper. \n",
    "                **** Normally you should return less than 8 source papers. ****\n",
    "                **** You can also infer the answer by evaluating the titles of each paper. ****\n",
    "               **** You should re-evaluate your answer by: Emphasize Novel Contributions: Instead of broadly asking for \"challenges\", explicitly ask for the novel contributions of the paper. This helps focus the search for references that directly contribute to those specific aspects.\n",
    "Prioritize Methodological Similarity: Instruct the search to prioritize references that share strong methodological similarities with the paper being analyzed. For example, papers that also employ minimax optimization or focus on sample efficiency in data augmentation.\n",
    "Look for Comparative Phrases: Guide the search towards phrases that indicate comparisons with previous work, such as \"Unlike [reference], we...\", \"Improving upon [reference], our method...\", or \"Similar to [reference] in terms of [aspect], but...\".\n",
    "#**** Please think step by step. Then, you should return your result in the json format, with the key is “reference number” and the value is “confidence score” between 0 and 1.'''\n",
    "    if author_note is not None:\n",
    "        part_note = f'''**** The author notes are: {author_note}, you can infer the answer based on this information'''     \n",
    "    else:\n",
    "        part_note = ''       \n",
    "                \n",
    "    part_text = f'''**** The text of the paper is:{text}'''\n",
    "\n",
    "    part_refs = f'''**** The titles of the references are: {refs_list}. You can infer the answer based on this information'''\n",
    "\n",
    "    return part1 + part_note + part_text + part_refs\n",
    "\n",
    "\n",
    "### 刷train\n",
    "total_prompt_train = {}\n",
    "for paper_key in tqdm(id_train):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "\n",
    "    raw_paper = [x for x in papers_train if x['_id'] == paper_key][0]\n",
    "    if 'notes' in raw_paper.keys():\n",
    "        note = raw_paper['notes']\n",
    "    else:\n",
    "        note = None\n",
    "    refs_list = submission_ref_list[paper_key]\n",
    "    my_prompt = get_prompt_gpt_short_5(text, author_note = note, refs_list = refs_list)\n",
    "    total_prompt_train[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_train_V2.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_train, f)\n",
    "\n",
    "\n",
    "total_prompt_test = {}\n",
    "for paper_key in tqdm(id_test):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "\n",
    "    raw_paper = [x for x in papers_test if x['_id'] == paper_key][0]\n",
    "    if 'notes' in raw_paper.keys():\n",
    "        note = raw_paper['notes']\n",
    "    else:\n",
    "        note = None\n",
    "    refs_list = submission_ref_list[paper_key]\n",
    "    my_prompt = get_prompt_gpt_short_5(text, author_note = note, refs_list = refs_list)\n",
    "    total_prompt_test[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test_V2.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_test, f)\n",
    "\n",
    "print(len(total_prompt_train), len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [00:00<00:00, 2951.00it/s]\n"
     ]
    }
   ],
   "source": [
    "### 第五类test: 考虑作者的note\n",
    "def get_prompt_gpt_short_note(text, notes):\n",
    "    return f'''**** I have a task to identify the source papers of a given paper, which author indicates that they inspire them most based on its text. \n",
    "                **** I will now give you a text of academic papers and the author's note of the paper. To find the most pertinent source papers:\n",
    "                Firstly, Understand the note given by arthor. Identify the main challenges and novel methods and approaches the paper introduces.\n",
    "                **** Then, find all  relevant source papers that the author based on the authors'note.\n",
    "                **** Please re-evaluate your result by the following metric: \t\tIs the main idea of paper p inspired by the reference？\n",
    "* \t\tIs the core method of paper p derived from the reference？\n",
    "* \t\tIs the reference essential for paper p? Without the work of this reference, paper p cannot be completed. \n",
    "*       Is the contribution of this reference paper mentioned in the author's note.\n",
    "Then, you should return your result in the json format, with the key is “reference number” (like b1, b2, ...) and the value is “confidence score” between 0 and 1.\n",
    "                **** The author's note is:{notes}\n",
    "                **** The text of the paper is:{text}'''\n",
    "\n",
    "total_prompt_test = {}\n",
    "for paper_key in tqdm(id_test):\n",
    "    file = paper_key + '.xml'\n",
    "    this_paper = papers_list[paper_key]\n",
    "    processed_body = this_paper.body_processed\n",
    "    text = extract_text(processed_body)\n",
    "    text = '.'.join([x for x in text])\n",
    "\n",
    "    raw_paper = [x for x in papers_test if x['_id'] == paper_key][0]\n",
    "    if 'notes' in raw_paper.keys():\n",
    "        note = raw_paper['notes']\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    refs_list = submission_ref_list[paper_key]\n",
    "\n",
    "    my_prompt = get_prompt_gpt_short_note(text, notes = note)\n",
    "    total_prompt_test[paper_key] = my_prompt\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test_note.pkl', 'wb') as f:\n",
    "    pickle.dump(total_prompt_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
