{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/b87bdh2x1kbcxmgsfhmgh1sh0000gn/T/ipykernel_4905/2617999452.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "### 目的：解析 GPT的结果\n",
    "import pickle \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读数据 - label数据\n",
    "import json\n",
    "with open('gpt4_res_parse_train_level.json', 'rb') as f:\n",
    "    total_prompt_train = json.load(f)\n",
    "\n",
    "with open('gpt4_res_parse_valid_level.json', 'rb') as f:\n",
    "    total_prompt_valid = json.load(f)\n",
    "\n",
    "with open('gpt4_res_parse_test_level.json', 'rb') as f:\n",
    "    total_prompt_test = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 目的：从GPT结果中解析出可以使用的数据\n",
    "import json\n",
    "import re\n",
    "\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "def find_b_references(text):\n",
    "    # 定义正则表达式模式，匹配'b'后跟着一个或多个数字\n",
    "    text = text.lower()\n",
    "    pattern = r'\\bb\\d+\\b'\n",
    "    \n",
    "    # 使用findall方法查找所有匹配的子串\n",
    "    # \\b 是一个单词边界，防止匹配到单词中的一部分\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def parse_gemini_res(text):\n",
    "    res = {}\n",
    "    geimini_result_list = text.split('paperkey')\n",
    "    for x in geimini_result_list:\n",
    "        try:\n",
    "            k, v = x.split('papervalue')\n",
    "            res[k] = v\n",
    "        except:\n",
    "            pass\n",
    "    return res\n",
    "\n",
    "def replace_references(text):\n",
    "    # 使用正则表达式查找所有的‘reference 数字’模式，并替换成‘[b数字]’格式\n",
    "    replaced_text = re.sub(r'reference (\\d+)', r'[b\\1]', text)\n",
    "    return replaced_text\n",
    "\n",
    "\n",
    "def process_input(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace('**direct inspiration', '. direct inspiration').replace('** direct inspiration', '. direct inspiration').replace('## direct inspiration', '. direct inspiration')\n",
    "    text = text.replace('**indirect inspiration', '. indirect inspiration').replace('** indirect inspiration', '. indirect inspiration').replace('## indirect inspiration', '. indirect inspiration')\n",
    "    text = text.replace('**other important', '. other important').replace('** other important', '. other important').replace('## other important', '. other important')\n",
    "    text = replace_references(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "def extract_references(input_text):\n",
    "    inspiration_types = {'Summary' : None,\n",
    "        's1': [],\n",
    "        's2': [],\n",
    "        's3': []\n",
    "    }\n",
    "    \n",
    "    #提取第一部分\n",
    "    #input_text = input_text.lower()\n",
    "    input_text = process_input(input_text)\n",
    "    text_step1 = input_text.split('\"direct inspiration\"')\n",
    "    summary = text_step1[0]\n",
    "    text_step2 = text_step1[1].split('\"indirect inspiration\"')\n",
    "    text_step3 = text_step2[1].split('\"other inspiration\"')\n",
    "    s1, s2, s3 = text_step2[0], text_step3[0], text_step3[1]\n",
    "    inspiration_types['summary'] = summary\n",
    "    inspiration_types['s1'] = find_b_references(s1)\n",
    "    inspiration_types['s2'] = find_b_references(s2)\n",
    "    inspiration_types['s3'] = find_b_references(s3)\n",
    "    return inspiration_types\n",
    "\n",
    "def extract_references_2(input_text):\n",
    "    inspiration_types = {'Summary' : None,\n",
    "        's1': [],\n",
    "        's2': [],\n",
    "        's3': []\n",
    "    }\n",
    "    input_text = input_text.lower()\n",
    "    input_text = input_text.replace(\"directinspiration\",\"direct inspiration\").replace(\"indirectinspiration\",\"indirect inspiration\").replace(\"otherinspiration\",\"other inspiration\")\n",
    "    try:\n",
    "        parse_res = json.loads(input_text.strip('```json\\n').strip('\\n```'))\n",
    "    except:\n",
    "        try:\n",
    "            parse_res = eval(input_text.strip('```json\\n').strip('\\n```'))\n",
    "        except:\n",
    "            return extract_references(input_text)\n",
    "        \n",
    "    try:\n",
    "        if 'references' not in parse_res['direct inspiration'].keys():\n",
    "            s1 = list(parse_res['direct inspiration'].keys())\n",
    "            s2 = list(parse_res['indirect inspiration'].keys())\n",
    "            s3 = list(parse_res['other inspiration'].keys())\n",
    "            inspiration_types['s1'].extend(s1)\n",
    "            inspiration_types['s2'].extend(s2)\n",
    "            inspiration_types['s3'].extend(s3)\n",
    "        else:\n",
    "            s1 = list(parse_res['references']['direct inspiration'].keys())\n",
    "            s2 = list(parse_res['references']['indirect inspiration'].keys())\n",
    "            s3 = list(parse_res['references']['other inspiration'].keys())\n",
    "            inspiration_types['s1'].extend(s1)\n",
    "            inspiration_types['s2'].extend(s2)\n",
    "            inspiration_types['s3'].extend(s3)\n",
    "            \n",
    "    except:\n",
    "        s1 = parse_res['direct inspiration']\n",
    "        s2 = parse_res['indirect inspiration']\n",
    "        s3 = parse_res['other inspiration']\n",
    "        inspiration_types['s1'].extend(s1)\n",
    "        inspiration_types['s2'].extend(s2)\n",
    "        inspiration_types['s3'].extend(s3)\n",
    "\n",
    "\n",
    "    return inspiration_types\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_result_train_level = {}\n",
    "for k, v in total_prompt_train.items():\n",
    "    res = []\n",
    "    for ii in range(5):\n",
    "        vv = v[ii]\n",
    "        res.append(extract_references_2(vv))\n",
    "    gpt4_result_train_level[k] = res\n",
    "\n",
    "\n",
    "gpt4_result_valid_level = {}\n",
    "for k, v in total_prompt_valid.items():\n",
    "    res = []\n",
    "    for ii in range(5):\n",
    "        vv = v[ii]\n",
    "        res.append(extract_references_2(vv))\n",
    "    gpt4_result_valid_level[k] = res\n",
    "\n",
    "gpt4_result_test_level = {}\n",
    "for k, v in total_prompt_test.items():\n",
    "    res = []\n",
    "    for ii in range(5):\n",
    "        vv = v[ii]\n",
    "        res.append(extract_references_2(vv))\n",
    "    gpt4_result_test_level[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt4_res_parse_train_level_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_result_train_level, f)\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_valid_level_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_result_valid_level, f)\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_level_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_result_test_level, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 第二部分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 读数据 - label数据\n",
    "import json\n",
    "with open('gpt4_res_parse_train.json', 'rb') as f:\n",
    "    total_prompt_train = json.load(f)\n",
    "\n",
    "with open('gpt4_res_parse_valid.json', 'rb') as f:\n",
    "    total_prompt_valid = json.load(f)\n",
    "\n",
    "with open('gpt4_res_parse_test_short.json', 'rb') as f:\n",
    "    total_prompt_test = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_res_parse_train_short = {}\n",
    "for k, v in  total_prompt_train.items():\n",
    "    res =  []\n",
    "    for i in range(5):\n",
    "        cleaned_string = v[i].strip('```json\\n')\n",
    "        res.append(json.loads(cleaned_string))\n",
    "        gpt4_res_parse_train_short[k] = res\n",
    "\n",
    "gpt4_res_parse_valid_short = {}\n",
    "for k, v in  total_prompt_valid.items():\n",
    "    res =  []\n",
    "    for i in range(5):\n",
    "        cleaned_string = v[i].strip('```json\\n')\n",
    "        res.append(json.loads(cleaned_string))\n",
    "        gpt4_res_parse_valid_short[k] = res\n",
    "\n",
    "gpt4_res_parse_test_short = {}\n",
    "for k, v in  total_prompt_test.items():\n",
    "    res =  []\n",
    "    for i in range(5):\n",
    "        cleaned_string = v[i].strip('```json\\n')\n",
    "        res.append(json.loads(cleaned_string))\n",
    "        gpt4_res_parse_test_short[k] = res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt4_res_parse_train_short_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_train_short, f)\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_valid_short_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_valid_short, f)\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_short_parsed.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_test_short, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPUS数据\n",
    "with open('opus_res_parse_test.json', 'rb') as f:\n",
    "    total_prompt_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [10:56<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "### 方式：让GPT4去提取结果\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= \"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")\n",
    "\n",
    "def get_prompt_text(text):\n",
    "    return f'''**** Your task is to extract the json answer from the text. The text is generated by a Large Language model to analyze an academic paper and return the import source papers. \n",
    "               **** Please return the result of the text in a json format, with the key is the reference number (Just keep the letter b and number like b1, b2...) and the value is the confidence score. The text is {text}'''\n",
    "\n",
    "opus_res_parse_test = {}\n",
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "          {  \"role\": \"user\",\n",
    "            \"content\": get_prompt_text(v),\n",
    "        }],\n",
    "        n = 1,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-3.5-turbo\")\n",
    "    opus_res_parse_test[k] = chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "opus_res_parse_json_test = {}\n",
    "for k, v in opus_res_parse_test.items():\n",
    "    opus_res_parse_json_test[k] = eval(v)\n",
    "\n",
    "import json\n",
    "with open('opus_res_parse_json_test.json', 'w') as f:\n",
    "    json.dump(opus_res_parse_json_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GPT4-turbo数据\n",
    "with open('gpt4_res_parse_test_only.json', 'rb') as f:\n",
    "    total_prompt_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_turbo_parse_test = {}\n",
    "\n",
    "for k, v in total_prompt_test.items():\n",
    "    res = []\n",
    "    for i in range(10):\n",
    "        vv = v[i].strip(\"```json\").strip(\"\\n```\")\n",
    "        try:\n",
    "            res.append(eval(vv))\n",
    "        except:\n",
    "            try:\n",
    "                res.append(json.loads(vv))\n",
    "            except:\n",
    "                res.append({'-1':'-1'})\n",
    "    gpt4_turbo_parse_test[k] = res\n",
    "\n",
    "\n",
    "with open('gpt4_turbo_res_parse_json_test.json', 'w') as f:\n",
    "    json.dump(gpt4_turbo_parse_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GPT4-turbo数据 V2\n",
    "with open('gpt4_res_parse_test_only_V2.json', 'rb') as f:\n",
    "    total_prompt_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/393 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [2:27:46<00:00, 22.56s/it]  \n"
     ]
    }
   ],
   "source": [
    "### 解析数据\n",
    "turbo_res_v2 = {}\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= \"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")\n",
    "\n",
    "def get_prompt_text(text):\n",
    "    return f'''**** Your task is to extract the json answer from the text. The text is generated by a Large Language model to analyze an academic paper and return the import source papers. \n",
    "               **** Please return the result of the text in a json format, with the key is the reference number (Just keep the letter b and number like b1, b2...) and the value is the confidence score. The text is {text}'''\n",
    "\n",
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    res = []\n",
    "    for ii in range(len(v)):\n",
    "        try:\n",
    "            vv = v[ii]\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                {  \"role\": \"user\",\n",
    "                    \"content\": get_prompt_text(vv),\n",
    "                }],\n",
    "                n = 1,\n",
    "                temperature=0.7,\n",
    "                model=\"gpt-3.5-turbo\")\n",
    "            res.append(chat_completion.choices[0].message.content)\n",
    "        except:\n",
    "            res.append({\"-1\":\"-1\"})\n",
    "    turbo_res_v2[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbo_res_v2_parse = {}\n",
    "for k, v in turbo_res_v2.items():\n",
    "    res = []\n",
    "    for ii in range(10):\n",
    "        try:\n",
    "            vv = v[0].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "            vvv = eval(vv)\n",
    "            tmp = {}\n",
    "            for aa, bb in vvv.items():\n",
    "                aa = aa.strip('[').strip(']')\n",
    "                tmp[aa] = bb\n",
    "            res.append(tmp)\n",
    "\n",
    "        except:\n",
    "            res.append({\"-1\":\"-1\"})\n",
    "    \n",
    "    turbo_res_v2_parse[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gpt4_turbo_res_parse_json_test_v2.json', 'w') as f:\n",
    "    json.dump(turbo_res_v2_parse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GPT4-note数据\n",
    "\n",
    "with open('GPT4_res_test_note.json', 'rb') as f:\n",
    "    GPT4_res_test_note = json.load(f)\n",
    "\n",
    "GPT4_res_test_note_parse = {}\n",
    "for k, v in GPT4_res_test_note.items():\n",
    "    res = []\n",
    "    for ii in range(10):\n",
    "        try:\n",
    "            vv = v[ii].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "            vvv = eval(vv)\n",
    "            tmp = {}\n",
    "            for aa, bb in vvv.items():\n",
    "                aa = aa.strip('[').strip(']')\n",
    "                tmp[aa] = bb\n",
    "            res.append(tmp)\n",
    "\n",
    "        except:\n",
    "            res.append({\"-1\":\"-1\"})\n",
    "    \n",
    "    GPT4_res_test_note_parse[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('GPT4_res_test_note_parse.json', 'w') as f:\n",
    "    json.dump(GPT4_res_test_note_parse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse gemini pro result 1\n",
    "### gemini数据\n",
    "with open('gemini_test_result_all.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "with open('gemini_test_result_all_round2.pkl', 'rb') as f:\n",
    "    total_prompt_test_round2 = pickle.load(f)\n",
    "\n",
    "with open('gemini_test_result_all_round3.pkl', 'rb') as f:\n",
    "    total_prompt_test_round3 = pickle.load(f)\n",
    "\n",
    "with open('gemini_test_result_all_round4.pkl', 'rb') as f:\n",
    "    total_prompt_test_round4 = pickle.load(f)\n",
    "\n",
    "gemini_res_parse_json_test = {}\n",
    "gemini_res_parse_json_test_round2 = {}\n",
    "gemini_res_parse_json_test_round3 = {}\n",
    "gemini_res_parse_json_test_round4 = {}\n",
    "\n",
    "for k, v in total_prompt_test.items():\n",
    "    try:\n",
    "        vv = v[0].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "        vvv = eval(vv)\n",
    "        tmp = {}\n",
    "        for aa, bb in vvv.items():\n",
    "            aa = aa.strip('[').strip(']')\n",
    "            tmp[aa] = bb\n",
    "        gemini_res_parse_json_test[k] = tmp\n",
    "\n",
    "    except:\n",
    "        gemini_res_parse_json_test[k] = {\"-1\":\"-1\"}\n",
    "    \n",
    "    try:\n",
    "        v = total_prompt_test_round2[k]\n",
    "        vv = v[0].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "        vvv = eval(vv)\n",
    "        tmp = {}\n",
    "        for aa, bb in vvv.items():\n",
    "            aa = aa.strip('[').strip(']')\n",
    "            tmp[aa] = bb\n",
    "        gemini_res_parse_json_test_round2[k] = tmp\n",
    "\n",
    "    except:\n",
    "        gemini_res_parse_json_test_round2[k] = {\"-1\":\"-1\"}\n",
    "\n",
    "    try:\n",
    "        v = total_prompt_test_round3[k]\n",
    "        vv = v[0].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "        vvv = eval(vv)\n",
    "        tmp = {}\n",
    "        for aa, bb in vvv.items():\n",
    "            aa = aa.strip('[').strip(']')\n",
    "            tmp[aa] = bb\n",
    "        gemini_res_parse_json_test_round3[k] = tmp\n",
    "\n",
    "    except:\n",
    "        gemini_res_parse_json_test_round3[k] = {\"-1\":\"-1\"}\n",
    "\n",
    "    try:\n",
    "        v = total_prompt_test_round4[k]\n",
    "        vv = v[0].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "        vvv = eval(vv)\n",
    "        tmp = {}\n",
    "        for aa, bb in vvv.items():\n",
    "            aa = aa.strip('[').strip(']')\n",
    "            tmp[aa] = float(bb)\n",
    "        gemini_res_parse_json_test_round4[k] = tmp\n",
    "\n",
    "    except:\n",
    "        gemini_res_parse_json_test_round4[k] = {\"-1\":\"-1\"}\n",
    "\n",
    "with open('gemini_res_parse_json_test.json', 'w') as f:\n",
    "    json.dump(gemini_res_parse_json_test, f)\n",
    "\n",
    "with open('gemini_res_parse_json_test_round2.json', 'w') as f:\n",
    "    json.dump(gemini_res_parse_json_test_round2, f)\n",
    "\n",
    "with open('gemini_res_parse_json_test_round3.json', 'w') as f:\n",
    "    json.dump(gemini_res_parse_json_test_round3, f)\n",
    "\n",
    "with open('gemini_res_parse_json_test_round4.json', 'w') as f:\n",
    "    json.dump(gemini_res_parse_json_test_round4, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parse data\n",
    "with open('GPT4_res_test_V3_save.json', 'rb') as f:\n",
    "    GPT4_res_test_V3_save = json.load(f)\n",
    "\n",
    "GPT4_res_test_V3_save_parse ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/393 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393/393 [1:14:56<00:00, 11.44s/it]\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key= \"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")\n",
    "\n",
    "def get_prompt_text(text):\n",
    "    return f'''**** Your task is to extract the json answer from the text. The text is generated by a Large Language model to analyze an academic paper and return the import source papers. \n",
    "               **** Please return the result of the text in a json format, with the key is the reference number (Just keep the letter b and number like b1, b2...) and the value is the confidence score. The text is {text}'''\n",
    "\n",
    "for k, v in tqdm(GPT4_res_test_V3_save.items()):\n",
    "    res = []\n",
    "    for ii in range(len(v)):\n",
    "        vv = v[ii]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                {  \"role\": \"user\",\n",
    "                    \"content\": get_prompt_text(vv),\n",
    "                }],\n",
    "                n = 1,\n",
    "                temperature=0.7,\n",
    "                model=\"gpt-3.5-turbo\")\n",
    "        res.append(chat_completion.choices[0].message.content)\n",
    "\n",
    "    GPT4_res_test_V3_save_parse[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GPT4_res_test_V3_save_parse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m GPT4_res_test_V3_parse_json \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mGPT4_res_test_V3_save_parse\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      3\u001b[0m     this_res \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GPT4_res_test_V3_save_parse' is not defined"
     ]
    }
   ],
   "source": [
    "GPT4_res_test_V3_parse_json = {}\n",
    "for k, v in GPT4_res_test_V3_save_parse.items():\n",
    "    this_res = []\n",
    "    for ii in range(len(v)):\n",
    "        try:\n",
    "            vv = v[ii].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "            vvv = eval(vv)\n",
    "            this_res.append(vvv)\n",
    "        except:\n",
    "            this_res.append({\"-1\":\"-1\"})\n",
    "    \n",
    "    GPT4_res_test_V3_parse_json[k] = this_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to json\n",
    "## save to json\n",
    "with open('GPT4_res_test_V3_parse.json', 'w') as f:\n",
    "    json.dump(GPT4_res_test_V3_parse_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
