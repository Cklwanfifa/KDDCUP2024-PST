{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  刷train数据\n",
    "\n",
    "## 调取GPT4-o接口\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key= \"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        }],\n",
    "        n = 10,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4-turbo\")\n",
    "\n",
    "        GPT4_res_test[k] = chat_completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_test_only = {}\n",
    "for k, v in GPT4_res_test.items():\n",
    "    this_res = []\n",
    "    for ii in range(10):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_test_only[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_only.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_test_only, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test_V2.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_test_V2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [3:39:32<00:00, 33.43s/it]  \n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test_V2.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        }],\n",
    "        n = 10,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4-turbo\")\n",
    "\n",
    "        GPT4_res_test_V2[k] = chat_completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_test_only_V2 = {}\n",
    "for k, v in GPT4_res_test_V2.items():\n",
    "    this_res = []\n",
    "    for ii in range(10):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_test_only_V2[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_only_V2.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_test_only_V2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_test_note.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_test_note = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [1:04:04<00:00, 11.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test_note.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": v[:35000],\n",
    "        }],\n",
    "        n = 10,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_test_note[k] = chat_completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_test_note_parse = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 341/341 [27:17<00:00,  4.80s/it]  \n"
     ]
    }
   ],
   "source": [
    "### 解析数据\n",
    "def get_prompt_text(text):\n",
    "    return f'''**** Your task is to extract the json answer from the text. The text is generated by a Large Language model to analyze an academic paper and return the import source papers. \n",
    "               **** Please return the result of the text in a json format, with the key is the reference number (Just keep the letter b and number like b1, b2...) and the value is the confidence score. The text is {text}'''\n",
    "\n",
    "for k, v in tqdm(GPT4_res_test_note.items()):\n",
    "    if k not in GPT4_res_test_note_parse.keys():\n",
    "        res = []\n",
    "        for ii in range(10):\n",
    "            content = v.choices[ii].message.content\n",
    "            chat_completion = client.chat.completions.create(\n",
    "                        messages=[\n",
    "                        {  \"role\": \"user\",\n",
    "                            \"content\": get_prompt_text(content),\n",
    "                        }],\n",
    "                        n = 1,\n",
    "                        temperature=0.7,\n",
    "                        model=\"gpt-3.5-turbo\")\n",
    "            res.append(chat_completion.choices[0].message.content)\n",
    "        GPT4_res_test_note_parse[k] = res\n",
    "    \n",
    "    if k in GPT4_res_test_note_parse.keys():\n",
    "        vv = GPT4_res_test_note_parse[k]\n",
    "        for ii in range(len(vv)):\n",
    "            if isinstance(vv[ii] , dict):\n",
    "                #重新刷一次\n",
    "                try:\n",
    "                    content = v.choices[ii].message.content\n",
    "                    chat_completion = client.chat.completions.create(\n",
    "                                messages=[\n",
    "                                {  \"role\": \"user\",\n",
    "                                    \"content\": get_prompt_text(content),\n",
    "                                }],\n",
    "                                n = 1,\n",
    "                                temperature=0.7,\n",
    "                                model=\"gpt-3.5-turbo\")\n",
    "                    GPT4_res_test_note_parse[k][ii] = chat_completion.choices[0].message.content\n",
    "                except:\n",
    "                    GPT4_res_test_note_parse[k][ii] = {\"-1\":\"-1\"}\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save GPT4_res_test_note_parse\n",
    "import json\n",
    "with open('GPT4_res_test_note.json', 'w') as f:\n",
    "    json.dump(GPT4_res_test_note_parse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788\n"
     ]
    }
   ],
   "source": [
    "### 补充刷20240528_get_prompt_gpt_detailed_train_V2.pkl\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_detailed_train_V2.pkl', 'rb') as f:\n",
    "    total_prompt_train = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_train_V2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [10:06:06<00:00, 46.15s/it]   \n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(total_prompt_train.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_train_V2.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        }],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_train_V2[k] = chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('get_prompt_gpt_detailed_test_V2.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_test))\n",
    "\n",
    "GPT4_res_test_V3 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [1:23:56<00:00, 12.78s/it]\n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test_V3.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        }],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4-turbo\")\n",
    "\n",
    "        GPT4_res_test_V3[k] = chat_completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save GPT4_res_train_V2 and GPT4_res_test_V3\n",
    "GPT4_res_train_V2_save = {}\n",
    "GPT4_res_test_V3_save = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in GPT4_res_train_V2.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    GPT4_res_train_V2_save[k] = this_res\n",
    "\n",
    "for k, v in GPT4_res_test_V3.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    GPT4_res_test_V3_save[k] = this_res\n",
    "\n",
    "## save to json\n",
    "with open('GPT4_res_train_V2_save.json', 'w') as f:\n",
    "    json.dump(GPT4_res_train_V2_save, f)\n",
    "\n",
    "with open('GPT4_res_test_V3_save.json', 'w') as f:\n",
    "    json.dump(GPT4_res_test_V3_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_train_V2_parse = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/784 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 784/784 [2:16:02<00:00, 10.41s/it]  \n"
     ]
    }
   ],
   "source": [
    "def get_prompt_text(text):\n",
    "    return f'''**** Your task is to extract the json answer from the text. The text is generated by a Large Language model to analyze an academic paper and return the import source papers. \n",
    "               **** Please return the result of the text in a json format, with the key is the reference number (Just keep the letter b and number like b1, b2...) and the value is the confidence score. The text is {text}'''\n",
    "\n",
    "for k, v in tqdm(GPT4_res_train_V2_save.items()):\n",
    "    res = []\n",
    "    for ii in range(len(v)):\n",
    "        vv = v[ii]\n",
    "        chat_completion = client.chat.completions.create(\n",
    "                messages=[\n",
    "                {  \"role\": \"user\",\n",
    "                    \"content\": get_prompt_text(vv),\n",
    "                }],\n",
    "                n = 1,\n",
    "                temperature=0.7,\n",
    "                model=\"gpt-3.5-turbo\")\n",
    "        res.append(chat_completion.choices[0].message.content)\n",
    "\n",
    "    GPT4_res_train_V2_parse[k] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_train_V2_parse_json = {}\n",
    "for k, v in GPT4_res_train_V2_parse.items():\n",
    "    this_res = []\n",
    "    for ii in range(len(v)):\n",
    "        try:\n",
    "            vv = v[ii].strip(\"```json\").strip(\"\\n```\").split(\"\\n```\")[0]\n",
    "            vvv = eval(vv)\n",
    "            this_res.append(vvv)\n",
    "        except:\n",
    "            this_res.append({\"-1\":\"-1\"})\n",
    "    \n",
    "    GPT4_res_train_V2_parse_json[k] = this_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save to json\n",
    "with open('GPT4_res_train_V2_parse.json', 'w') as f:\n",
    "    json.dump(GPT4_res_train_V2_parse_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
