{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/56/b87bdh2x1kbcxmgsfhmgh1sh0000gn/T/ipykernel_2399/509512801.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 394 394\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_train.pkl', 'rb') as f:\n",
    "    total_prompt_train = pickle.load(f)\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_valid.pkl', 'rb') as f:\n",
    "    total_prompt_valid = pickle.load(f)\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_json_3_test.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_train), len(total_prompt_valid), len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  刷train数据\n",
    "\n",
    "## 调取GPT4-o接口\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key= \"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")\n",
    "\n",
    "GPT4_res_train = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [2:04:41<00:00,  9.49s/it]  \n"
     ]
    }
   ],
   "source": [
    "### 开始刷数据\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 刷train数据\n",
    "for k, v in tqdm(total_prompt_train.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_train.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_train[k] = chat_completion\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_train = {}\n",
    "for k, v in GPT4_res_train.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_train[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_train_level.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['```json\\n{\\n  \"Summary\": \"The paper addresses the challenge of name disambiguation in academic profiles, proposing a novel algorithm called CONNA to improve matching accuracy by capturing both exact and semantic matches. It highlights the limitations of traditional feature-engineering methods and representation-based models, and introduces an interaction-based model to better handle the nuances of name disambiguation. The paper also integrates a self-correcting mechanism through reinforcement learning.\",\\n  \"Direct Inspiration\": {\\n    \"b4\": 0.9,\\n    \"b12\": 0.85,\\n    \"b52\": 0.8\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b1\": 0.75,\\n    \"b56\": 0.7,\\n    \"b57\": 0.7\\n  },\\n  \"Other Inspiration\": {\\n    \"b27\": 0.6,\\n    \"b37\": 0.6\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n    \"Summary\": \"The paper addresses the challenge of accurately matching academic papers with their respective authors, focusing on capturing both exact and soft semantic matches. The proposed algorithm, CONNA, integrates interaction-based models and reinforcement learning to improve matching and decision accuracy.\",\\n    \"Direct Inspiration\": {\\n        \"b1\": 0.9,\\n        \"b4\": 0.8,\\n        \"b12\": 0.85,\\n        \"b56\": 0.9,\\n        \"b52\": 0.75\\n    },\\n    \"Indirect Inspiration\": {\\n        \"b6\": 0.65,\\n        \"b14\": 0.7,\\n        \"b18\": 0.6,\\n        \"b23\": 0.6,\\n        \"b31\": 0.5,\\n        \"b45\": 0.5,\\n        \"b57\": 0.6\\n    },\\n    \"Other Inspiration\": {\\n        \"b8\": 0.4,\\n        \"b27\": 0.4,\\n        \"b34\": 0.4,\\n        \"b37\": 0.4,\\n        \"b43\": 0.3,\\n        \"b9\": 0.3,\\n        \"b15\": 0.3,\\n        \"b24\": 0.3,\\n        \"b29\": 0.3,\\n        \"b30\": 0.3,\\n        \"b38\": 0.3,\\n        \"b54\": 0.3,\\n        \"b0\": 0.25\\n    }\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses the challenge of accurate name disambiguation in academic datasets, proposing an algorithm that combines traditional feature-engineering methods with representation-based models to capture both exact and semantic matches. The proposed CONNA framework integrates a matching component and a decision component, fine-tuning them through reinforcement learning to self-correct errors.\",\\n  \"Direct Inspiration\": {\\n    \"b1\": 1,\\n    \"b56\": 1\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b4\": 0.8,\\n    \"b12\": 0.8,\\n    \"b52\": 0.8\\n  },\\n  \"Other Inspiration\": {\\n    \"b8\": 0.6,\\n    \"b34\": 0.6,\\n    \"b27\": 0.6\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses the challenge of accurately matching target papers to the correct authors in academic datasets, considering both exact and semantic matches. The proposed algorithm, CONNA, integrates feature-engineering and representation-based methods, leveraging reinforcement learning to fine-tune the matching and decision components.\",\\n  \"Direct Inspiration\": {\\n    \"b4\": 0.9,\\n    \"b12\": 0.85,\\n    \"b52\": 0.8\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b1\": 0.75,\\n    \"b56\": 0.7,\\n    \"b57\": 0.65\\n  },\\n  \"Other Inspiration\": {\\n    \"b6\": 0.6,\\n    \"b18\": 0.55,\\n    \"b23\": 0.5\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses the problem of name disambiguation in academic datasets by proposing an end-to-end framework named CONNA. The primary challenge is to capture both exact and soft matches between candidate names and target pairs while accounting for semantic drift and historical errors. The proposed algorithm uses interaction-based models and reinforcement learning to jointly fine-tune matching and decision components.\",\\n  \"Direct Inspiration\": {\\n    \"b1\": 0.95,\\n    \"b56\": 0.95,\\n    \"b4\": 0.90,\\n    \"b12\": 0.90,\\n    \"b52\": 0.90\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b37\": 0.80,\\n    \"b31\": 0.75,\\n    \"b6\": 0.75\\n  },\\n  \"Other Inspiration\": {\\n    \"b18\": 0.70,\\n    \"b23\": 0.70,\\n    \"b25\": 0.70,\\n    \"b45\": 0.70,\\n    \"b57\": 0.70\\n  }\\n}\\n```']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_key = list(gpt4_res_parse_train.keys())[0]\n",
    "gpt4_res_parse_train[train_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 开始刷数据-valid\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "GPT4_res_valid = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [1:01:35<00:00,  9.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# 刷valid数据\n",
    "for k, v in tqdm(total_prompt_valid.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_valid.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_valid[k] = chat_completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_valid = {}\n",
    "for k, v in GPT4_res_valid.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_valid[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_valid_level.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_valid, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['```json\\n{\\n  \"Summary\": \"The paper addresses challenges in graph representation learning, particularly in improving the expressive power of graph embeddings through unsupervised or self-supervised methods. It proposes the AutoProNE framework, which automatically selects graph filters for smoothing graph representations using AutoML. The framework is inspired by recent advancements in self-supervised learning and novel graph filters, aiming to enhance graph embeddings without manual filter design.\",\\n  \"Direct Inspiration\": [\"b14\", \"b15\"],\\n  \"Indirect Inspiration\": [\"b3\", \"b10\"],\\n  \"Other Inspiration\": [\"b9\", \"b12\", \"b21\"]\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses challenges in graph representation learning, focusing on enhancing the expressive power of embeddings through optimized propagation techniques. Specifically, it proposes an automated framework, AutoProNE, to select the best graph filters for smoothing embeddings in an unsupervised manner, leveraging advancements in self-supervised learning and AutoML.\",\\n  \"Direct Inspiration\": {\\n    \"b14\": 1.0,\\n    \"b15\": 1.0\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b10\": 0.8,\\n    \"b11\": 0.8\\n  },\\n  \"Other Inspiration\": {\\n    \"b3\": 0.6,\\n    \"b9\": 0.6\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses the challenges of improving graph representation learning through unsupervised/self-supervised methods, focusing on enhancing the propagation step with automated graph filters. The AutoProNE framework is proposed to automatically select the best graph filters using AutoML, thereby improving the expressive power of learned graph representations.\",\\n  \"Direct Inspiration\": {\\n    \"b14\": 1.0,\\n    \"b15\": 1.0\\n  },\\n  \"Indirect Inspiration\": {\\n    \"b9\": 0.8,\\n    \"b10\": 0.7,\\n    \"b11\": 0.7\\n  },\\n  \"Other Inspiration\": {\\n    \"b0\": 0.6,\\n    \"b3\": 0.6\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n  \"Summary\": \"The paper addresses the challenge of enhancing graph representation learning through automatic selection of graph filters in a self-supervised manner. Inspired by simplified graph convolutional models (SGC) and the ProNE model, the proposed AutoProNE framework aims to improve the expressive power of graph embeddings by focusing on the propagation and smoothing steps. The framework uses AutoML to automatically select the best graph filters for each specific graph dataset.\",\\n  \"Direct Inspiration\": {\\n    \"b14\": 1.0,\\n    \"b15\": 1.0\\n  },\\n  \"Indirect Inspiration\": {},\\n  \"Other Inspiration\": {\\n    \"b3\": 0.7,\\n    \"b10\": 0.7,\\n    \"b11\": 0.7\\n  }\\n}\\n```',\n",
       " '```json\\n{\\n    \"Summary\": \"The paper addresses the challenges of improving graph representation learning by focusing on the propagation step, aiming to enhance the expressive power of embeddings in an unsupervised or self-supervised manner. The proposed AutoProNE framework leverages AutoML to automatically select appropriate graph filters for different datasets, avoiding manual design. The method is inspired by simplifying GCNs and the use of Gaussian filters in ProNE, and seeks to provide a general approach to representation smoothing.\",\\n    \"Direct Inspiration\": {\\n        \"b14\": 1,\\n        \"b15\": 1\\n    },\\n    \"Indirect Inspiration\": {\\n        \"b0\": 0.8,\\n        \"b9\": 0.7,\\n        \"b10\": 0.7,\\n        \"b11\": 0.7\\n    },\\n    \"Other Inspiration\": {\\n        \"b12\": 0.6,\\n        \"b13\": 0.6\\n    }\\n}\\n```']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_key = list(gpt4_res_parse_valid.keys())[0]\n",
    "gpt4_res_parse_valid[valid_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT4_res_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 394/394 [51:49<00:00,  7.89s/it]\n"
     ]
    }
   ],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_test[k] = chat_completion\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_test = {}\n",
    "for k, v in GPT4_res_test.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_test[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_level.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
