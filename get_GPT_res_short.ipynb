{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maggiewang/anaconda3/envs/xeek2/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, dirname\n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict as dd\n",
    "from bs4 import BeautifulSoup   \n",
    "from fuzzywuzzy import fuzz\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 394 394\n"
     ]
    }
   ],
   "source": [
    "## 调取GPT4-o接口\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\", base_url=\"YOUR_BASE_URL\")#4.0\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_train.pkl', 'rb') as f:\n",
    "    total_prompt_train = pickle.load(f)\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_valid.pkl', 'rb') as f:\n",
    "    total_prompt_valid = pickle.load(f)\n",
    "\n",
    "import pickle\n",
    "with open('20240528_get_prompt_gpt_short_3_test.pkl', 'rb') as f:\n",
    "    total_prompt_test = pickle.load(f)\n",
    "\n",
    "print(len(total_prompt_train), len(total_prompt_valid), len(total_prompt_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 开始刷数据\n",
    "GPT4_res_train = {}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 刷train数据\n",
    "for k, v in tqdm(total_prompt_train.items()):\n",
    "    flag = True\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_train[k] = chat_completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 有error 重新刷\n",
    "# 刷train数据\n",
    "for k, v in tqdm(total_prompt_train.items()):\n",
    "\n",
    "    if k in GPT4_res_train.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_train[k] = chat_completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_train = {}\n",
    "for k, v in GPT4_res_train.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_train[k] = this_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt4_res_parse_train.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  刷valid数据\n",
    "GPT4_res_valid = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 开始刷数据-valid\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 刷train数据\n",
    "for k, v in tqdm(total_prompt_valid.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_valid.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_valid[k] = chat_completion\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_valid = {}\n",
    "for k, v in GPT4_res_valid.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_valid[k] = this_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('gpt4_res_parse_valid.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 刷test数据\n",
    "GPT4_res_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tqdm(total_prompt_test.items()):\n",
    "    flag = True\n",
    "\n",
    "    if k in GPT4_res_test.keys():\n",
    "        continue\n",
    "\n",
    "    if len(v) > 100000:\n",
    "        continue\n",
    "    \n",
    "    if flag:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"You are an expert in analyzing academic paper. You have a strong background in science and you are very good at logic reasoning. when return the result, please do not return the process of thinking. just return the result in the json format, with the key is “reference number” (b1, b2, ...) and the value is “confidence score” between 0 and 1.\"}\n",
    "        ,{   \n",
    "            \"role\": \"user\",\n",
    "            \"content\": v,\n",
    "        },],\n",
    "        n = 5,\n",
    "        temperature=0.7,\n",
    "        model=\"gpt-4o\")\n",
    "\n",
    "        GPT4_res_test[k] = chat_completion\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 储存结果\n",
    "gpt4_res_parse_test = {}\n",
    "for k, v in GPT4_res_test.items():\n",
    "    this_res = []\n",
    "    for ii in range(5):\n",
    "        this_res.append(v.choices[ii].message.content)\n",
    "    gpt4_res_parse_test[k] = this_res\n",
    "\n",
    "import json\n",
    "with open('gpt4_res_parse_test_short.json', 'w') as f:\n",
    "    json.dump(gpt4_res_parse_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xeek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
